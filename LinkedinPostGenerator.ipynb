{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0414b45-01cc-4760-84f2-e787e8940c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/atharv/.local/lib/python3.10/site-packages (1.75.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (4.6.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: sniffio in /home/atharv/.local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/atharv/.local/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/atharv/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/atharv/.local/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in /home/atharv/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: certifi in /home/atharv/.local/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/atharv/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/atharv/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/atharv/.local/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2cff99fb-0c86-45db-8c98-bb03bc89e37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "openai_client = OpenAI(api_key=\"sk-\")\n",
    "ASSISTANT_ID = \"asst_kTfFkImWj1AkkkCea9AXFJZA\"  # Your assistant ID\n",
    "POST_WRITER_ASSISTANT_ID = \"asst_jwJfa6mtMpdBSJovmeJYVSFy\"\n",
    "MARKDOWN_FILE_PATH  = \"user_posts_summary.md\"  # File containing scraped posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5db4e0e4-fdd2-4cce-9e81-7b08019a709d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_file(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        upload = openai_client.files.create(file=file, purpose=\"assistants\")\n",
    "        return upload.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e3204824-15a5-4656-ac4f-e645ea2cb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_assistant(assistant_id, thread_id, file_ids, content):\n",
    "    try:\n",
    "        # Attach files to message\n",
    "        openai_client.beta.threads.messages.create(\n",
    "            thread_id=thread_id,\n",
    "            role=\"user\",\n",
    "            content=content,\n",
    "            attachments=[\n",
    "                {\n",
    "                    \"file_id\": file_id,\n",
    "                    \"tools\": [{\"type\": \"file_search\"}],\n",
    "                }\n",
    "                for file_id in file_ids\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Create and poll run\n",
    "        run = openai_client.beta.threads.runs.create_and_poll(\n",
    "            assistant_id=assistant_id,\n",
    "            thread_id=thread_id,\n",
    "        )\n",
    "\n",
    "        if run.last_error:\n",
    "            raise Exception(run.last_error.message)\n",
    "\n",
    "        return fetch_response(thread_id, run.id)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error running assistant: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Fetch assistant response\n",
    "# -----------------------\n",
    "def fetch_response(thread_id, run_id):\n",
    "    messages = openai_client.beta.threads.messages.list(\n",
    "        thread_id=thread_id, run_id=run_id\n",
    "    )\n",
    "\n",
    "    if not messages:\n",
    "        raise ValueError(\"No messages found.\")\n",
    "\n",
    "    latest_message = messages.data[0]\n",
    "    content_block = latest_message.content[0].text\n",
    "\n",
    "    annotations = content_block.annotations\n",
    "    response_text = content_block.value\n",
    "\n",
    "    citations = []\n",
    "    for i, annotation in enumerate(annotations):\n",
    "        response_text = response_text.replace(annotation.text, f\"[{i}]\")\n",
    "        if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "            cited_file = openai_client.files.retrieve(file_citation.file_id)\n",
    "            citations.append(f\"[{i}] {cited_file.filename}\")\n",
    "\n",
    "    return response_text\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Save Markdown Output\n",
    "# -----------------------\n",
    "def save_response_markdown(text, filename=\"assistant_response.md\"):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(text)\n",
    "    print(f\"ğŸ“ Saved response to {filename}\")\n",
    "\n",
    "\n",
    "def extract_json_block(text):\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        matches = re.findall(r'\\[\\s*{.*?}\\s*\\]', text, re.DOTALL)\n",
    "        if matches:\n",
    "            try:\n",
    "                return json.loads(matches[0])\n",
    "            except json.JSONDecodeError:\n",
    "                return []\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f05f6de-cb90-4b60-addd-f8be8abf0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Running LinkedIn Content Assistant...\n",
      "ğŸ“‚ Uploading the scrapped posts...\n",
      "ğŸ’¬ Asking assistant for analysis + post generation...\n",
      "ğŸ“ Saved response to assistant_response.md\n",
      "ğŸ” Preview of tagging assistant response:\n",
      " ```json\n",
      "[\n",
      "    {\n",
      "        \"post_id\": \"Post 1\",\n",
      "        \"text\": \"VCs, CPG investors, and consumer brand foundersâ€”this event is for you!\\n\\nğŸŒï¸â€â™€ï¸LvlUp Ventures East Hampton Invitational\\nA Mini-Golf Showdown + High-Growth CPG Networking Experience\\nğŸ“… June 5 | East Hampton | Part of Hamptons Tech Week\\n\\\n",
      "\n",
      "âœï¸ Generating post variations...\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 1:\n",
      "ğŸŒï¸ Calling all VCs, CPG investors, and brand founders! Don't miss this:\n",
      "\n",
      "LvlUp Ventures East Hampton Invitational:\n",
      "ğŸ“… June 5 | East Hampton | Hamptons Tech Week\n",
      "\n",
      "An exclusive event mixing mini-golf, CPG networking, and more:\n",
      "â›³ Mini-golf tourney | ğŸ¤ Founders-investor reception\n",
      "ğŸª Gourmet bites + drinks | ğŸ Curated gift bags\n",
      "\n",
      "Exciting additions:\n",
      "ğŸ‰ joins as our headline sponsor.\n",
      "ğŸ° Treats from a sweet specialist.\n",
      "ğŸŒ¿ Better-for-you snacks on deck.\n",
      "\n",
      "Tastings from top brands:\n",
      "ğŸ« Clean superfoods | ğŸª Health-forward bakes\n",
      "ğŸ¥œ Luxe nuts + dried fruits\n",
      "\n",
      "Limited space! RSVP now to secure your spot. Let's connect! ğŸ”—\n",
      "#CPGevent #VCnetworking #BrandFounders #SummerFun #EastHampton #NetworkingOpportunity #CPGbrands #InvestorConnections #ExclusiveTastings #MiniGolfMadness\n",
      "\n",
      "ğŸ‘‡ Lock in your spot today! ğŸ‘‡\n",
      "ğŸ”—\n",
      "\n",
      "ğŸ¯ Modified Version: ğŸŒï¸ Calling all VCs, CPG investors, and brand founders to our exclusive event:\n",
      "\n",
      "LvlUp Ventures East Hampton Invitational:\n",
      "Join us for an afternoon mixing mini-golf, CPG networking, and curated indulgences!\n",
      "Limited spaceâ€”RSVP now! ğŸ”—\n",
      "#CPGevent #ConnectionOpportunity #ExclusiveNetworking #SummerNetworking #RSVPnow #CPGbrands #InvestorConnections #MiniGolfMadness #HamptonsTechWeek #NetworkingFun\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 2:\n",
      "Here is a LinkedIn post based on the provided content and tags:\n",
      "\n",
      "ğŸš¨ Are you raising a Pre-Seed or Seed Round? Connect with 15+ top VCs in <5 minutes.\n",
      "\n",
      "ğŸ“Œ Like & drop your company name + one-liner. Let's fast-track your funding journey!\n",
      "\n",
      "ğŸ’¡ Fundraising made easy at LvlUp Ventures. No more cold outreach, just warm intros.\n",
      "\n",
      "We engage with VCs at Lâ€™OrÃ©al CVC and other top firms to boost your startup. ğŸš€\n",
      "\n",
      "Letâ€™s pave the way to your startup's success. Comment to kickstart your funding! ğŸ‘‡\n",
      "\n",
      "#FundingOpportunity #StartupNetworking #VCConnection #SeedRound #PreSeedRound\n",
      "\n",
      "Feel free to provide feedback if you would like to see a modified version!\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 3:\n",
      "ğŸš€ What We Look for in Startups at LvlUp Ventures ğŸš€\n",
      "Investing in bold Seed-stage startups with a unique vision and execution drive.\n",
      "\n",
      "Scrappy entrepreneurs catch our eyeâ€”those who challenge norms and deliver results.\n",
      "\n",
      "Emphasizing innovation and resilience, we seek startups that stand out from the crowd.\n",
      "\n",
      "Get in touch if your startup embodies these qualities! #SeedStage #Innovation #Entrepreneurship\n",
      "\n",
      "ğŸ”¹ğŸ”¹ğŸ”¹\n",
      "\n",
      "ğŸ¯ Modified Version:\n",
      "Investing in bold Seed-stage startups with a unique vision and execution drive.\n",
      "\n",
      "Seeking scrappy entrepreneurs who challenge norms and deliver results. #LvlUpVentures #InvestmentCriteria\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 196:\n",
      "Here is a LinkedIn post based on the content provided:\n",
      "\n",
      "ğŸŒŸ Exciting Update in the world of #bitcoin and #cryptocurrency! Stay informed: [Read more](https://lnkd.in/gqTnvkqw)\n",
      "\n",
      "Are you ready to dive into the latest trends and insights in the crypto sphere?\n",
      "\n",
      "Join the conversation on the future of digital assets and blockchain technology.\n",
      "\n",
      "Invest wisely and stay ahead in the fast-evolving cryptocurrency landscape.\n",
      "\n",
      "Educate yourself on the potentials and risks of investing in Bitcoin and other cryptocurrencies.\n",
      "\n",
      "Stay updated on market fluctuations and key announcements impacting the crypto market.\n",
      "\n",
      "â„¹ï¸ Explore more about the evolving world of cryptocurrencies: [Link](https://lnkd.in/gqTnvkqw)\n",
      "\n",
      "Let's engage and learn together in the world of digital currencies! ğŸš€\n",
      "\n",
      "#cryptocurrency #blockchain #investmentopportunity #bitcoinnews #cryptoexchange #knowledgeiskey\n",
      "\n",
      "ğŸ¯ Modified Version: Are you ready to explore the latest in #bitcoin and #cryptocurrency? Stay informed: [Read more](https://lnkd.in/gqTnvkqw)\n",
      "\n",
      "Discover the future of digital assets and blockchain with us!\n",
      "\n",
      "Engage with the evolving world of cryptocurrencies and make informed decisions.\n",
      "\n",
      "Stay ahead in the dynamic crypto space with our insightful updates.\n",
      "\n",
      "Learn about the opportunities and challenges of crypto investments.\n",
      "\n",
      "Stay tuned for market insights and breaking news in the crypto industry.\n",
      "\n",
      "ğŸ” Dive into the world of digital currencies: [Link](https://lnkd.in/gqTnvkqw)\n",
      "\n",
      "Let's grow our knowledge together in the exciting realm of cryptocurrencies! ğŸ’¡\n",
      "\n",
      "#cryptotrading #blockchaintechnology #investmentstrategy #cryptoanalysis #digitalcurrency #alwayslearning\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 197:\n",
      "ğŸŒŸ What a delightful evening in Bel Air! Honored to mingle with LP Wendy Diamond, visionary founder Doug Evans, and the talented Jacob Ringel.\n",
      "\n",
      "Such an inspiring gathering, connecting with brilliant minds shaping the future.\n",
      "\n",
      "Let's keep the momentum going! Share your key takeaways and connect with us. \n",
      "\n",
      "#BelAirNetworking #InnovativeMinds #CommunityEngagement #BuildingConnections #PositiveVibes\n",
      "\n",
      "ğŸ¯ Modified Version:\n",
      "ğŸŒŸ Enjoying a fantastic Bel Air evening with LP Wendy Diamond, founder Doug Evans, and team member Jacob Ringel.\n",
      "\n",
      "Exciting networking time with industry leaders. Share your highlights and connect with us.\n",
      "\n",
      "Keep the conversation going! Share insights and connect with our community.\n",
      "\n",
      "#BelAirNetworking #InnovatorsCircle #CommunityConnections #InspiringMoments #PositiveVibes\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 198:\n",
      "ğŸŒŸ Celebrating Black History Month with Founder Stories! ğŸŒŸ\n",
      "\n",
      "As Black History Month wraps up, we unveil our latest Founder Story. Join us in honoring Bishop B. Curry IV, a young innovator dedicated to saving lives. At just 11, Bishop created Oasis, a device preventing heat-related tragedies in hot cars.\n",
      "\n",
      "Stay tuned for bi-weekly launches on our website and LinkedIn!\n",
      "\n",
      "ğŸ‘‰ Learn more about Bishop B. Curry IV's inspiring journey here â¤µ\n",
      "â€¦more\n",
      "\n",
      "#DiversityPromotion #Inspiration #BlackHistoryMonth #FounderStory #Innovation\n",
      "\n",
      "---\n",
      "\n",
      "ğŸ¯ Modified Version:\n",
      "Celebrating an Inspiring Founder for Black History Month!\n",
      "\n",
      "Join us in honoring Bishop B. Curry IV, an innovator saving lives. Discover his incredible journey and Oasis deviceâ€”an innovation in child safety.\n",
      "\n",
      "Stay tuned for more Founder Stories on our website and LinkedIn!\n",
      "\n",
      "Explore Bishop B. Curry IV's story here â¤µ\n",
      "â€¦more\n",
      "\n",
      "#BlackHistory #InspiringInnovation #FounderHighlight #DiversityInTech #Inspiration\n",
      "\n",
      "ğŸ“¬ Post Variations for Post 199:\n",
      "ğŸŒŸ **ISO ğŸ‘€** ğŸŒŸ\n",
      "\n",
      "Beauty friends- seeking packaging team/supplier for low MOQs. Tag recommendations below or DM! Let's partner! \n",
      "\n",
      "#BeautyIndustry #PackagingSupplier #StartupCollaboration #LowMOQ #Networking\n",
      "\n",
      "ğŸš€ **Call-to-Action:** Share your recommendations or DM directly to connect! ğŸ“¦ğŸ¤\n",
      "\n",
      "---\n",
      "\n",
      "ğŸ¯ **Modified Version:** \n",
      "\n",
      "ğŸŒŸ **Request for Recommendations** ğŸŒŸ\n",
      "\n",
      "Seeking packaging team/supplier for low MOQs in beauty industry. Tag or DM suggestions to partner! \n",
      "\n",
      "#PackagingSolutions #StartupNeeds #BeautyPackaging #Collaboration #Networking\n",
      "\n",
      "ğŸš€ **Call-to-Action:** Tag your recommendations or DM directly to collaborate! ğŸ“¦ğŸ¤\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸš€ Running LinkedIn Content Assistant...\")\n",
    "\n",
    "    # Upload file\n",
    "    print(\"ğŸ“‚ Uploading the scrapped posts...\")\n",
    "    file_id = upload_file(MARKDOWN_FILE_PATH )\n",
    "\n",
    "    # Create thread\n",
    "    thread = openai_client.beta.threads.create()\n",
    "\n",
    "    # Send prompt to assistant\n",
    "    print(\"ğŸ’¬ Asking assistant for analysis + post generation...\")\n",
    "    response = process_assistant(\n",
    "        assistant_id=ASSISTANT_ID,\n",
    "        thread_id=thread.id,\n",
    "        file_ids=[file_id],\n",
    "        content=(\n",
    "    \"The uploaded file is a **Markdown file containing multiple LinkedIn posts**.\\n\"\n",
    "    \"Each post is structured using Markdown headers and follows this format:\\n\\n\"\n",
    "    \"## Post {number}\\n\"\n",
    "    \"**Author:** ...\\n\"\n",
    "    \"**Reposted by:** ...\\n\"\n",
    "    \"**Timestamp:** ...\\n\"\n",
    "    \"**Reactions:** ...\\n\"\n",
    "    \"**Comments:** ...\\n\"\n",
    "    \"**Reposts:** ...\\n\"\n",
    "    \"**Media Type:** ...\\n\"\n",
    "    \"**Has Image:** ...\\n\"\n",
    "    \"**Has Article:** ...\\n\"\n",
    "    \"**Post URL:** ...\\n\"\n",
    "    \"**Content:**\\n\"\n",
    "    \"{body text of the post}\\n\\n\"\n",
    "    \"---\\n\\n\"\n",
    "\n",
    "    \"### Your task:\\n\"\n",
    "    \"1. Detect and split the file into individual posts using `## Post` headers.\\n\"\n",
    "    \"2. For **each post**, analyze the `**Content:**` section.\\n\"\n",
    "    \"3. Assign tags in these four categories **based only on the post content**:\\n\"\n",
    "    \"- **Content Type**: e.g., Educational Insight, Case Study, Thought Leadership, etc.\\n\"\n",
    "    \"- **Tone / Audience Reaction**: e.g., Empowering, Reflective, Optimistic, etc.\\n\"\n",
    "    \"- **Structure**: e.g., Narrative, Instructional, Listicle, etc.\\n\"\n",
    "    \"- **Intent / Objective**: e.g., Personal Branding, Lead Generation, Community Building, etc.\\n\\n\"\n",
    "\n",
    "    \"### Output format:\\n\"\n",
    "    \"Return a **JSON array**, where each item looks like this:\\n\\n\"\n",
    "    \"```json\\n\"\n",
    "    \"[\\n\"\n",
    "    \"  {\\n\"\n",
    "    \"    \\\"post_id\\\": \\\"Post 1\\\",\\n\"\n",
    "    \"    \\\"text\\\": \\\"(The main post content here)\\\",\\n\"\n",
    "    \"    \\\"tags\\\": {\\n\"\n",
    "    \"      \\\"content_type\\\": [\\\"...\\\"],\\n\"\n",
    "    \"      \\\"tone\\\": [\\\"...\\\"],\\n\"\n",
    "    \"      \\\"structure\\\": [\\\"...\\\"],\\n\"\n",
    "    \"      \\\"intent\\\": [\\\"...\\\"]\\n\"\n",
    "    \"    }\\n\"\n",
    "    \"  },\\n\"\n",
    "    \"  ...\\n\"\n",
    "    \"]\\n\"\n",
    "    \"```\\n\\n\"\n",
    "    \"âš ï¸ Do not summarize or group the posts.\\n\"\n",
    "    \"Each post must be processed and tagged **independently**.\\n\"\n",
    "    \"Only return the raw JSON array. No additional text or explanations.\"\n",
    "),\n",
    "\n",
    "\n",
    "\n",
    "    )\n",
    "\n",
    "    # Save and parse response\n",
    "    tagged_posts = []\n",
    "    if response:\n",
    "        save_response_markdown(response)\n",
    "        print(\"ğŸ” Preview of tagging assistant response:\\n\", response[:300])\n",
    "        tagged_posts = extract_json_block(response)\n",
    "        if not tagged_posts:\n",
    "            print(\"âŒ Failed to extract JSON array from response. Exiting.\")\n",
    "            exit()\n",
    "\n",
    "    # Step 3: Generate new posts from tags\n",
    "    print(\"\\nâœï¸ Generating post variations...\\n\")\n",
    "    for post in tagged_posts:\n",
    "        content = post.get(\"text\", \"\")\n",
    "        tags = post.get(\"tags\", {})\n",
    "\n",
    "        if not content.strip():\n",
    "            continue\n",
    "\n",
    "        writer_thread = openai_client.beta.threads.create()\n",
    "        writer_prompt = f\"\"\"\n",
    "You are a skilled LinkedIn post creator. Using the content and tags below, create variations of the post.\n",
    "\n",
    "Content:\n",
    "{content}\n",
    "\n",
    "Tags:\n",
    "{json.dumps(tags, indent=2)}\n",
    "\n",
    "Each paragraph must contain 12-15 words (max 20). Add a blank line between paragraphs.\n",
    "\n",
    "End with a call-to-action and 5-10 relevant hashtags.\n",
    "\n",
    "At the end, if the user provides feedback (e.g., \"more playful\", \"shorter\", \"less emoji\"), show a ğŸ¯ Modified Version based on that feedback.\n",
    "\"\"\"\n",
    "\n",
    "        post_response = process_assistant(\n",
    "            assistant_id=POST_WRITER_ASSISTANT_ID,\n",
    "            thread_id=writer_thread.id,\n",
    "            file_ids=[],\n",
    "            content=writer_prompt,\n",
    "        )\n",
    "\n",
    "        print(f\"ğŸ“¬ Post Variations for {post['post_id']}:\\n{post_response}\\n\")\n",
    "\n",
    "\n",
    "    openai_client.beta.threads.delete(thread.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9f3b79-beef-4b28-a30c-6bb64774a3a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4c1f3e-f41e-4bff-bfb8-f0816dd14a59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
